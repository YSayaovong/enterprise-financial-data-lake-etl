# ğŸ¦ Case Study: Eliminating Manual Financial Reporting With a Scalable Data Lake Pipeline  
**Enterprise ETL System for Automated Financial Analytics & KPI Standardization**

## âœ… Executive Summary  
The finance organization of a mid-sized company struggled with slow, inconsistent reporting.  
Analysts spent **4â€“6 hours every month** manually pulling CSVs, merging spreadsheets, and recalculating KPIsâ€”leading to:

- Conflicting revenue totals across business units  
- Delayed month-end close  
- No single source of truth for financial KPIs  
- Limited drill-down capability without rebuilding spreadsheets  

To solve this, a fully automated **Financial Data Lake + ETL Pipeline** was engineered, replacing all manual steps and enabling real-time, repeatable analytics.

---

# âœ… Step 1 â€” Financial Data Ingestion Into the Data Lake (Raw Zone)

All incoming financial dataâ€”GL extracts, transactions, expense logs, forecast submission filesâ€”are automatically routed into the **S3 raw zone**.

### âœ… ETL Enhancements  
- Enforced standardized file naming conventions  
- Automated ingestion scripts replaced manual file drops  
- Metadata tagging for traceability and audit readiness  
- Timestamped storage ensures historical integrity  

### ğŸ“Š Pipeline Summary View  
![Financial BI Dashboard Summary](https://github.com/YSayaovong/financial-data-engineering-etl-pipeline/blob/main/Screenshots/ETL-Financial-BI-Dashboard-Summary.png)

This ensures consistent, traceable ingestion for all financial datasets required for reporting and forecasting.

---

# âœ… Step 2 â€” Transformation Layer Using Apache Spark

Spark processes the raw files and transforms them into fully curated financial datasets.

### âœ… Transformation Logic  
- Schema alignment across months and departments  
- Cleansing invalid/empty records  
- Hierarchical joins (Revenue â†” Cost â†” Product â†” GL â†” Cost Center)  
- Time-series rollups: **MoM, YoY, QTD, YTD**  
- Deduplication and strict data type enforcement  

### ğŸ“ˆ ETL KPI Flow  
![ETL KPI Flow](https://github.com/YSayaovong/financial-data-engineering-etl-pipeline/blob/main/Screenshots/financial_etl_kpi.PNG)

These curated tables populate the **analytics zone**, ready for consumption by downstream BI tools.

---

# âœ… Step 3 â€” KPI Modeling & Automated Data Quality Enforcement  

After transformation, the pipeline computes standardized financial KPIs used across FP&A and Accounting:

### âœ… Standard Financial Metrics  
- Revenue  
- COGS  
- Gross Margin  
- Operating Expenses (OPEX)  
- Net Income  
- Forecast vs Actual Variance  
- Rolling 12-Month Trends  

### âœ… Data Quality Monitoring  
The pipeline automatically flags:

- Negative or inconsistent revenue  
- Invalid GL accounts  
- Missing cost center mappings  
- Forecast misalignments  
- Duplicate month entries  

### ğŸ“Š KPI Summary Model  
![KPI Summary](https://github.com/YSayaovong/financial-data-engineering-etl-pipeline/blob/main/Screenshots/kpi_summary.PNG)

Finance teams no longer waste time reconciling mismatched spreadsheets.

---

# âœ… Step 4 â€” BI Delivery Through Power BI  

Curated datasets feed into a Power BI financial model that provides:

### âœ… Executive-Level Reporting  
- Revenue & expense trendlines  
- Gross margin KPIs  
- Forecast vs actual analysis  
- Department-level drill-downs  
- Month-to-date & quarter-to-date performance  
- Automated variance visuals  

The dashboard refreshes daily, giving leadership near real-time visibility.

### ğŸ“Š Power BI Dashboard Output  
![Power BI Dashboard](https://github.com/YSayaovong/financial-data-engineering-etl-pipeline/blob/main/Screenshots/power_bi.PNG)

---

# âœ… Step 5 â€” Business Impact  

After one quarter of adopting the automated financial pipeline:

- âœ… Manual reporting time decreased **by 80%**  
- âœ… KPIs became standardized across Accounting, Finance, and FP&A  
- âœ… Month-end close accelerated  
- âœ… CFO gained same-day insight into financial performance  
- âœ… Analysts focused on strategy instead of spreadsheet processing  
- âœ… Data lake became the backbone for reporting, forecasting, and audit support  

This ETL pipeline now serves as the companyâ€™s **financial analytics operating system**, enabling reliable, consistent, and scalable financial reporting.

---

# âœ… Tools & Technologies  
- AWS S3 (Data Lake Raw & Analytics Zones)  
- Apache Spark (ETL Transformation)  
- Python (Data Processing Logic)  
- Power BI (Executive Dashboards)  
- Financial Modeling (Variance, Margin, Trend Analysis)  
- Git/GitHub for version control  

---

# âœ… Summary  
This project demonstrates how an engineered data lake pipeline can modernize financial reporting by automating ingestion, enforcing data integrity, and delivering real-time dashboards.  
The result is a scalable architecture that replaces error-prone spreadsheets with a controlled, enterprise-grade financial analytics environment.

